{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Machine Learning Operations Project","text":"<p>The following pages contain some basic documentation for our project for MLOps course at DTU 2025. We created a baseline model and used a pretrained model from huggingface (timm) to predict pneunomia for an X-Ray image dataset.</p>"},{"location":"#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    modeltraining.md  # Markdown for our model training and other related functions\n    api.md # Markdown page for api \ndockerfiles/\nexperiments/\nmodels/\nsrc/chest_xray_diagnosis/\n    __pycache__/\n    configs/\n        sweep.yaml\n    logs/\n    site/\n    __innit__.py\n    api.py\n    data.py\n    evaluate.py\n    frontend.py\n    model.py\n    train.py\n    visualize.py\ntests/\n    __init__.py\n    test_api.py\n    test_data.py\n    test_model.py\nREADME.md\nrequirements_dev.txt\nrequirements_tests.tx\nrequirements.txt\ntasks.py\n</code></pre>"},{"location":"api/","title":"API","text":""},{"location":"api/#src.chest_xray_diagnosis.api.health_check","title":"<code>src.chest_xray_diagnosis.api.health_check()</code>","text":"<p>Health check endpoint to verify API is running.</p> Source code in <code>src/chest_xray_diagnosis/api.py</code> <pre><code>@app.get(\"/\")\ndef health_check():\n    \"\"\"Health check endpoint to verify API is running.\"\"\"\n    return {\"message\": \"API is up and running!\"}\n</code></pre>"},{"location":"api/#src.chest_xray_diagnosis.api.predict","title":"<code>src.chest_xray_diagnosis.api.predict(file=File(...))</code>  <code>async</code>","text":"<p>Endpoint for image classification using the trained model. Input: An image file Output: Predicted class and probabilities</p> Source code in <code>src/chest_xray_diagnosis/api.py</code> <pre><code>@app.post(\"/predict/\")\nasync def predict(file: UploadFile = File(...)):\n    \"\"\"\n    Endpoint for image classification using the trained model.\n    Input: An image file\n    Output: Predicted class and probabilities\n    \"\"\"\n    \"\"\"Predict sentiment of the input text.\"\"\"\n    request_counter.inc()\n    try:\n        # Read the uploaded image\n        image_bytes = await file.read()\n        image = Image.open(io.BytesIO(image_bytes)).convert(\"RGB\")\n\n        # Preprocess the image\n        image = test_transform(image).unsqueeze(0).to(device)  # Add batch dimension and move to device\n\n        # Perform inference\n        with torch.no_grad():\n            outputs = model(image)  # Forward pass\n            probabilities = torch.softmax(outputs, dim=1).cpu().numpy()[0]  # Convert logits to probabilities\n            predicted_class = probabilities.argmax()  # Get the class with the highest probability\n\n        return {\n            \"predicted_class\": int(predicted_class),  # Convert to int for JSON compatibility\n            \"probabilities\": probabilities.tolist(),  # Convert numpy array to list\n        }\n    except Exception as e:\n        error_counter.inc()\n        raise HTTPException(status_code=500, detail=f\"Prediction error: {e}\")\n</code></pre>"},{"location":"modeltraining/","title":"Basemodel functions","text":""},{"location":"modeltraining/#src.chest_xray_diagnosis.evaluate","title":"<code>src.chest_xray_diagnosis.evaluate</code>","text":""},{"location":"modeltraining/#src.chest_xray_diagnosis.evaluate.main","title":"<code>main(model_name=typer.Option('Pretrained', help='Name of the model to evaluate.'), batch_size=typer.Option(64, help='Batch size for data loaders.'), device_type=typer.Option(None, help=\"Device to run evaluation (e.g., 'cuda', 'cpu', 'mps').\"), pretrained=typer.Option('True', help='Use a pretrained model (True) or baseline model (False).'))</code>","text":"<p>Main CLI entry point for evaluating the CNN model.</p> Source code in <code>src/chest_xray_diagnosis/evaluate.py</code> <pre><code>@app.command()\ndef main(\n    model_name: str = typer.Option(\"Pretrained\", help=\"Name of the model to evaluate.\"),\n    batch_size: int = typer.Option(64, help=\"Batch size for data loaders.\"),\n    device_type: str = typer.Option(None, help=\"Device to run evaluation (e.g., 'cuda', 'cpu', 'mps').\"),\n    pretrained: str = typer.Option(\"True\", help=\"Use a pretrained model (True) or baseline model (False).\"),\n):\n    \"\"\"\n    Main CLI entry point for evaluating the CNN model.\n    \"\"\"\n    logger.info(\"Starting evaluation script\")\n\n    print(\n        \"Using CUDA\" if torch.cuda.is_available() else \"Using MPS\" if torch.backends.mps.is_available() else \"Using CPU\"\n    )\n    device = torch.device(\n        device_type or (\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n    )\n\n    # Load test data\n    global testset\n    testset = data_loader(train=False)\n    test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=0)\n\n    logger.info(f\"Device selected: {device}\")\n    logger.info(f\"Using pretrained model: {pretrained}\")\n    # Load the model\n    model_path = os.path.join(\"models\", f\"{model_name}.pt\")\n    if pretrained == \"True\":\n        model = create_model(\"mobilenetv3_small_050.lamb_in1k\", pretrained=True)\n        model.reset_classifier(num_classes=2)\n        logger.info(\"Initialized pretrained model\")\n    else:\n        model = CNN_Baseline(num_classes=2)\n        logger.info(\"Initialized baseline model\")\n\n    # Load model weights\n    if not os.path.exists(model_path):\n        logger.error(f\"Model checkpoint not found at {model_path}\")\n        raise FileNotFoundError(f\"Model checkpoint not found at {model_path}\")\n    model.load_state_dict(torch.load(model_path, map_location=device))\n    logger.info(f\"Loaded model weights from {model_path}\")\n\n    # Move the model to the device\n    model.to(device)\n\n    # Loss function\n    loss_fn = nn.CrossEntropyLoss()\n\n    # Evaluate the model\n    logger.info(\"Starting evaluation process\")\n    evaluate(model=model, criterion=loss_fn, test_loader=test_loader, device=device, name=model_name)\n    logger.info(\"Evaluation complete\")\n</code></pre>"},{"location":"modeltraining/#src.chest_xray_diagnosis.model.CNN_Baseline","title":"<code>src.chest_xray_diagnosis.model.CNN_Baseline</code>","text":"<p>               Bases: <code>Module</code></p> Source code in <code>src/chest_xray_diagnosis/model.py</code> <pre><code>class CNN_Baseline(nn.Module):\n    def __init__(self, num_classes=2):\n        super(CNN_Baseline, self).__init__()\n        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n\n        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n\n        self.fc1 = nn.Linear(32 * 32 * 32, num_classes)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.max_pool2d(x, 2)\n\n        x = F.relu(self.conv2(x))\n        x = F.max_pool2d(x, 2)\n\n        x = x.view(x.size(0), -1)\n\n        x = self.fc1(x)\n\n        return x\n\n    def save(self, filename):\n        torch.save(self.state_dict(), filename)\n\n    def load(self, filename):\n        self.load_state_dict(torch.load(filename))\n</code></pre>"},{"location":"modeltraining/#src.chest_xray_diagnosis.train","title":"<code>src.chest_xray_diagnosis.train</code>","text":""},{"location":"modeltraining/#src.chest_xray_diagnosis.train.main","title":"<code>main(num_epochs=typer.Option(2, help='Number of epochs for training.'), batch_size=typer.Option(64, help='Batch size for data loaders.'), learning_rate=typer.Option(0.001, help='Learning rate for the optimizer.'), model_name=typer.Option('Pretrained', help='Name of the model.'), device_type=typer.Option(None, help=\"Device to run training (e.g., 'cuda', 'cpu', 'mps').\"), pretrained=typer.Option('True', help='Use a pre-trained model.'), use_wandb=typer.Option('False', help='Enable or disable logging to Weights and Biases.'))</code>","text":"<p>Main CLI entry point for training the CNN model.</p> Source code in <code>src/chest_xray_diagnosis/train.py</code> <pre><code>@app.command()\ndef main(\n    num_epochs: int = typer.Option(2, help=\"Number of epochs for training.\"),\n    batch_size: int = typer.Option(64, help=\"Batch size for data loaders.\"),\n    learning_rate: float = typer.Option(1e-3, help=\"Learning rate for the optimizer.\"),\n    model_name: str = typer.Option(\"Pretrained\", help=\"Name of the model.\"),\n    device_type: str = typer.Option(None, help=\"Device to run training (e.g., 'cuda', 'cpu', 'mps').\"),\n    pretrained: str = typer.Option(\"True\", help=\"Use a pre-trained model.\"),\n    use_wandb: str = typer.Option(\"False\", help=\"Enable or disable logging to Weights and Biases.\"),\n):\n    \"\"\"Main CLI entry point for training the CNN model.\"\"\"\n    logger.info(\"Starting training script\")\n    print(\n        \"Using CUDA\" if torch.cuda.is_available() else \"Using MPS\" if torch.backends.mps.is_available() else \"Using CPU\"\n    )\n    global device\n    device = torch.device(\n        device_type or (\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n    )\n\n    global trainset, train_loader, test_loader\n    trainset = data_loader(train=True)\n    train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=0)\n    testset = data_loader(train=False)\n    test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=0)\n\n    logger.info(f\"Device selected: {device}\")\n    logger.info(f\"Using pretrained model: {pretrained}\")\n\n    if pretrained == \"False\":\n        model_name = \"Baseline\"\n\n    if pretrained == \"True\":\n        model = create_model(\"mobilenetv3_small_050.lamb_in1k\", pretrained=True)\n        model.reset_classifier(num_classes=2)\n        model.to(device)\n        logger.info(\"Initialized pretrained model\")\n    else:\n        model = CNN_Baseline(num_classes=2).to(device)\n        logger.info(\"Initialized baseline model\")\n\n    hyperparams = {\n        \"num_epochs\": num_epochs,\n        \"batch_size\": batch_size,\n        \"learning_rate\": learning_rate,\n        \"model_name\": model_name,\n        \"device\": device.type,\n        \"pretrained\": pretrained,\n    }\n\n    if wandb_available and use_wandb == \"True\":\n        try:\n            wandb.init(\n                project=\"xray\",\n                entity=\"tassios1999-danmarks-tekniske-universitet-dtu\",\n                config=hyperparams,\n                name=f\"{model_name}_{current_date}\"\n            )\n        except wandb.errors.UsageError as e:\n            logger.warning(f\"Failed to initialize wandb: {e}. Proceeding without wandb.\")\n            use_wandb = False\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n    loss_fn = nn.CrossEntropyLoss()\n    logger.info(\"Starting training\")\n\n\n    train(\n        model=model,\n        optimizer=optimizer,\n        criterion=loss_fn,\n        num_epochs=num_epochs,\n        name=model_name,\n        use_wandb=use_wandb == \"True\",\n        hyperparams=hyperparams\n    )\n    logger.info(\"Training complete\")\n\n    if wandb_available and use_wandb:\n        wandb.finish()\n</code></pre>"},{"location":"modeltraining/#src.chest_xray_diagnosis.train.train","title":"<code>train(model, optimizer, criterion, num_epochs=10, name='CNN', use_wandb=False, hyperparams=None)</code>","text":"<p>Train the CNN model</p> Source code in <code>src/chest_xray_diagnosis/train.py</code> <pre><code>def train(model, optimizer, criterion, num_epochs=10, name=\"CNN\", use_wandb=False, hyperparams = None):\n    \"\"\"Train the CNN model\"\"\"\n    out_dict = {\"name\": name, \"train_acc\": [], \"test_acc\": [], \"train_loss\": [], \"test_loss\": []}\n\n    logger.info(\"Hyperparameters used:\")\n    logger.info(hyperparams)\n\n    for epoch in tqdm(range(num_epochs), unit=\"epoch\"):\n        logger.info(f\"Starting epoch {epoch + 1}/{num_epochs}\")\n        model.train()\n        # For each epoch\n        train_correct = 0\n        train_loss = []\n        for minibatch_no, (data, target) in tqdm(enumerate(train_loader), total=len(train_loader), desc=\"DataLoader\"):\n            data, target = data.to(device), target.to(device)\n            # Zero the gradients computed for each weight\n            optimizer.zero_grad()\n            # Forward pass your image through the network\n            output = model(data)\n            # Compute the loss\n            loss = criterion(output, target)\n            # Backward pass through the network\n            loss.backward()\n            # Update the weights\n            optimizer.step()\n\n            train_loss.append(loss.item())\n            # Compute how many were correctly classified\n            predicted = output.argmax(1)\n            train_correct += (target == predicted).sum().cpu().item()\n\n        out_dict[\"train_acc\"].append(train_correct / len(trainset))\n        out_dict[\"train_loss\"].append(np.mean(train_loss))\n\n        logger.info(\n            f\"Epoch {epoch + 1}/{num_epochs}: Train Loss: {np.mean(train_loss):.3f}, Train Accuracy: {out_dict['train_acc'][-1] * 100:.1f}%\"\n        )\n\n        if wandb_available and use_wandb:\n            wandb.log(\n                {\n                    \"epoch\": epoch + 1,\n                    \"train_loss\": np.mean(train_loss),\n                    \"train_accuracy\": out_dict[\"train_acc\"][-1] * 100,\n                }\n            )\n\n        # Save the model and visualizations\n        if epoch == num_epochs - 1:\n            # File and Directory Paths\n            model_dir = \"models\"\n            plots_dir = \"plots\"\n            os.makedirs(plots_dir, exist_ok=True)\n            metrics_plot_path = os.path.join(plots_dir, \"metrics.png\")\n\n            # Create Directories if They Don't Exist\n            os.makedirs(model_dir, exist_ok=True)\n            os.makedirs(os.path.dirname(metrics_plot_path), exist_ok=True)\n\n            # Save Model\n            model_path = os.path.join(model_dir, f\"{name}_{current_date}.pt\")\n            torch.save(model.state_dict(), model_path)\n\n            # Save Visualizations\n            plot_metrics([out_dict], metrics_plot_path)\n\n            logger.info(f\"Model saved at {model_path}\")\n            logger.info(f\"Metrics plot saved at {metrics_plot_path}\")\n\n    return out_dict\n</code></pre>"},{"location":"modeltraining/#src.chest_xray_diagnosis.visualize","title":"<code>src.chest_xray_diagnosis.visualize</code>","text":""}]}